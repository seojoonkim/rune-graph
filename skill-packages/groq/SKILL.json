{
  "name": "groq",
  "displayName": "Groq",
  "description": "Groq LPU inference engine for ultra-fast Llama and Mixtral inference. Ideal for latency-sensitive AI pipelines.",
  "vendor": "Groq",
  "emoji": "⚡",
  "tagline": "Blazing-fast LLM inference — 500+ tokens/second.",
  "category": "ai",
  "version": "1.1.0",
  "verified": true,
  "docsUrl": "https://console.groq.com/docs",
  "downloads": 38000,
  "stars": 720,
  "skills": [
    "groq-chat",
    "groq-stream"
  ]
}
